{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING FOR TIME SERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "#time decorator\n",
    "\n",
    "def time_estimator(func):\n",
    "    def wrapper (*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"Elapsed time: {elapsed:.2f} seconds\")\n",
    "        return result\n",
    "    return wrapper \n",
    "\n",
    "def forecast_plot(y_train, y_test, y_pred, target_name):\n",
    "    \n",
    "    import seaborn as sns\n",
    "    last_row_history = pd.Series(y_train[-1])\n",
    "    last_row_history.index = [y_train.index[-1]]\n",
    "    \n",
    "    y_pred_plot = y_pred.append(last_row_history)\n",
    "    y_pred_plot = y_pred_plot.sort_index()\n",
    "    \n",
    "    if y_test.empty==True: \n",
    "        sns.set(style =\"whitegrid\")\n",
    "        plt.figure(figsize=(11,4))\n",
    "        plt.title(\"Forecast results\")\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel(f'{target_name}')\n",
    "                              \n",
    "    sns.lineplot(data = y_train, marker = 'o')\n",
    "    sns.lineplot(data = y_pred_plot, marker = 'o')\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.grid(False)\n",
    "    pit.legend(['History', \"Forecast\"])\n",
    "    return None\n",
    "\n",
    "    y_test_plot = y_test.append(last_row_history)\n",
    "    y_test_plot = y_test_plot.sort_index()\n",
    "    \n",
    "    sns.set(style =\"whitegrid\")\n",
    "    plt.figure(figsize=(11,4))\n",
    "    plt.title(\"Overall results\")\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(f'{target_name}')\n",
    "    sns.lineplot(data = y_train, marker = 'o')\n",
    "    sns.lineplot(data = y_test_plot, marker = 'o')\n",
    "    sns.lineplot(data = y_pred_plot, marker = 'o')\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.grid(False)\n",
    "    plt.legend(['History', \"Test\", \"Forecast\"])\n",
    "    \n",
    "    sns.set(style =\"whitegrid\")\n",
    "    plt.figure(figsize=(11,4))\n",
    "    plt.title(\"Forecast vs test\")\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(f'{target_name}')\n",
    "    sns.lineplot(data = y_test_plot, marker = 'o')\n",
    "    sns.lineplot(data = y_pred_plot, marker = 'o')\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.grid(False)\n",
    "    plt.legend([\"Test\", \"Forecast\"])\n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity = eod.filter( (F.col(\"ric\")==\"TSLA.0\") | (F.col(\"ric\")==\"TSLA.0Q\") )\n",
    "equity = equity.toPandas() \n",
    "equity = equity.drop_duplicates(subset ='loaddate')\n",
    "equity = equity.sort_values(\"loaddate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "equity database colums:\n",
    "\n",
    "- loaddate --> Date in format dd/mm/yy\n",
    "- Volume --> End of day traded Volume\n",
    "- 1 single equity ticker considered\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time estimator\n",
    "def Feature_engineering_volume(df):\n",
    "    tsp = df[[ 'week', 'loaddate', 'closeprice', 'openprice', 'volume ']l\n",
    "    ts = spark. createDataFrame(tsp)\n",
    "    ts = ts.orderBy(col(\"loaddate\") )\n",
    "    ts = ts.select(\"loaddate\" , \"volume\", \"closeprice\", \"openprice\")\n",
    "    ts = ts.withColumn(\"group\" ,F.lit(\"1\") )\n",
    "    windowSpec = Window.partitionBy(\"group\").orderBy(\"loaddate\")\n",
    "    ts = ts.withColumn(\"lag1\", F. lag(\"volume\" , 1).over(windowSpec))\n",
    "    w = Window().partitionBy(F.col('group')).orderBy('loaddate').rowsBetween(-9, 0)\n",
    "    ts = ts.withColumn(\"rollingmean\", F.avg(\"volume\").over(w))\n",
    "    \n",
    "    def computeweights(n):\n",
    "        random_n = np.random.exponential(scale=1, size=n)\n",
    "        sum_n = np.sum(random_n)\n",
    "        scaled = (random_n / sum_n) * 100\n",
    "        scaled.sort()\n",
    "        return scaled\n",
    "    \n",
    "    def generate_exp_weights(n):\n",
    "        weights = computeweights(n)\n",
    "        n=1000\n",
    "        distribution = computeweights(n)\n",
    "        plt. plot(distribution)\n",
    "        return weights \n",
    "\n",
    "    weights = generate_exp_weights(10)\n",
    "    w = Window().partitionBy(F.col('group')).orderBy('loaddate').rowsBetween(-9, 0)\n",
    "\n",
    "    ts = ts.withColumn('data', sort_array(collect_list(struct('loaddate', 'volume')).over(w))) \\ \n",
    "            .withColumn('idx', expr(\"array_position(data, (loaddate, volume)) -1\" )) \\\n",
    "            .withColumn('weights', F.array([F.lit(x) for x in weights] )) \\\n",
    "            .withColumn('sum weights', expr(\"aggregate(weights, 0D, (acc,x) -› acc+x)\"))\n",
    "\n",
    "    ts = ts.withColumn('rollingweightedmean', \n",
    "                       expr(\"\"\" aggregate( \n",
    "                           zip_with(data, weights, (x,y) -> x.volume*y),\n",
    "                           0D,\n",
    "                           (acc, x) -› асс+х, \n",
    "                           acc -> acc/sum_weights) \"\"\"))\n",
    "\n",
    "    ts = ts.drop(\"data\", \"idx\", \"weights\", \"sum_ weights\")\n",
    "    ts = ts.withColumn('rollingweightedmean', F.coalesce(ts.rollingweightedmean,ts.rollingmean))\n",
    "    ts = ts.withColumn(\"sequencetime\", row_number().over(Window.orderBy(\"loaddate\")) )\n",
    "    ts = ts.withColumn(\"sequencetime_exp\", F.col(\"sequencetime\")**2 )\n",
    "\n",
    "    ts = ts.withColumn(\"lead1\", F.lead(\"volume\").over(windowSpec)) \\\n",
    "            .withColumn(\"lead2\", F.lead(\"volume\", 2).over(windowspec) \\\n",
    "            .withColumn(\"lead3\" , F.lead(\"volume\", 3).over.(windowSpec) \\\n",
    "            .withColumn(\"lag1\" , F.lag(\"volume\" , 1).over(windowSpec) ) \\\n",
    "            .withColumn(\"lag2\", F.lag(\"volume\" ,2).over(windowSpec) ) \\\n",
    "            .withColumn(\"lag3\", F.lag(\"volume\" , 3).over(windowSpec) )\n",
    "\n",
    "    ts = ts.withColumn( 'lag1' , F.coalesce(ts.lag1, ts.volume))\n",
    "    ts = ts.withColumn('lag2' ,F.coalesce(ts.lag2,ts.lag1))\n",
    "    ts = ts.withColumn('lag3', F.coalesce(ts.lag3, ts.lag2))\n",
    "    ts = ts.withColumn ('lead1', F.coalesce(ts.lead1,ts.volume))\n",
    "    ts = ts.withColumn ('lead2' F.coalesce(ts.lead2,ts.lead1))\n",
    "    ts = ts.withColumn ('lead3', F.coalesce(ts.lead3,ts.lead2))\n",
    "\n",
    "    growing_flag = (F.col(\"volume\") > F.col(\"lag1\")) & (F.col(\"volume\") > F.col(\"lag2\")) \\\n",
    "                        & (F.col(\"volume\") > F.col(\"lag3\"))\n",
    "    falling_flag = (F.col(\"volume\") > F.col(\"lead1\")) & (F.col(\"volume\") > F.col(\"lead2\")) & \n",
    "                        (F.col(\"volume\") > F.col(\"lead3\")) \n",
    "    ts = ts.withColumn(\"growing_flag\", F.when(growing_flag, 1). otherwise(0) ) \\\n",
    "            .withColumn (\"falling_flag\", F.when(falling_flag, 1). otherwise(0) )\n",
    "\n",
    "    ts = ts.withColumn(\"changepoint\", F.when((F.col(\"growing_flag\")==1) & (F.col(\"falling_flag\")==1) , 1).otherwise(0))\n",
    "                        \\ .drop(\"growing_flag\", \"falling_flag\")\n",
    "\n",
    "    ts = ts.withColumn(\"changelag1\", F.lag(\"changepoint\").over(windowSpec)) \\\n",
    "            .withColumn(\"changelag2\", F.lag(\"changepoint\", 2).over(windowSpec) ) \\\n",
    "            .withColumn(\"changelag3\", F.lag(\"changepoint\", 3).over(windowSpec) ) \n",
    "\n",
    "    ts = ts.withColumn(\"changepoint_confirm\", F.when( (F.col(\"changepoint\")==1) & (F.col(\"changelag1\")!=1) \\\n",
    "                                                     & (F.col(\"changelag2\")!=1) & (F.col(\"changelag3\")!=1) , 1).otherwise(0) ) \n",
    "\n",
    "    ts = ts.withColumn(\"changepoint_up\", F.when((F.co1(\"changepoint_confirm\")==1) & (F.col(\"volume\") > F.col(\"lag1\") ), 1).otherwise(0) ) \\\n",
    "                       .withColumn(\"changepoint _down\", F.when( (F.col(\"changepoint_confirm\")==1) & (F.col(\"volume\")< F.col(\"lag1\") ), 1).otherwise(0) )\n",
    "\n",
    "    ts = ts.withColumn(\"trendgroup\", F.sum(F.col(\"changepoint_confirm\")).over(Window.orderBy(\"loaddate\")))\n",
    "    ts = ts.withColumn(\"trendgroup\", F.when(F.col(\"changepoint_confirm\")==1, F.col(\"trendgroup\")-1).otherwise(F.col(\"trendgroup\")))\n",
    "\n",
    "\n",
    "\n",
    "    windowTrend = Window().partitionBy(F.col('trendgroup')).orderBy('loaddate')\n",
    "    ts = ts.withColumn(\"seq_within_trendgroup\" ,F.row_number).over(windowTrend))\n",
    "    changes = ts.select(\"trendgroup\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "    trend_expr = [F.when(F.col(\"trendgroup\") == ch, 1).otherwise(0).alias(\"Trend_n_\" + str(ch) ) for ch in changes]\n",
    "\n",
    "    cols = ts.columns\n",
    "    for c in trend_expr:\n",
    "        cols.append(c)\n",
    "\n",
    "    ts = ts.select(cols)\n",
    "    trend_list = [col for col in ts.columns if \"Trend_n_\" in col]\n",
    "\n",
    "    for trend in trend_list: \n",
    "        ts = ts.withColumn(trend+\"_lag\",F.lag(F.col(trend)).over(windowSpec) ) \n",
    "        n = int(trend.split(\"_\")[-1])            \n",
    "        if n!=0:\n",
    "            past_col = \"Trend_n_\" + str(n-1)\n",
    "            ts = ts.withColumn(trend+\"_turnpoint\", F.when( (F.col(trend+\"_lag\")==0) & (F.col(trend)==1) & \\ \n",
    "                            (F.col(past_col)==0), F.col(\"loaddate\")).otherwise(0))\n",
    "\n",
    "    turnpoint_list = [col for col in ts.columns if \"_turnpoint\" in col]\n",
    "    for turnpoint in turnpoint list:\n",
    "        turn = ts.select(turnpoint).filter(F.col(turnpoint)!=\"0\").first()[0]\n",
    "        ts = ts.withColumn(turnpoint, F when(F. col(\"loaddate\") >= turn, 1).otherwise (0) )\n",
    "        #ts = ts. withCoLumn (turnpoint, F. row_number (). over (Window(). partitionBy(F. col(turnpoint)). orderBy( 'Loaddate')))\n",
    "\n",
    "    turnpoint_list = [col for col in ts.columns if \"_turnpoint\" in col]\n",
    "    for turnpoint in turnpoint_list:\n",
    "\n",
    "        ts = ts.withColumn(turnpoint + \"_2\" , F.row_number().over(Window().partitionBy(F.col(turnpoint)).orderBy('loaddate')))\n",
    "        ts = ts.withColumn(turnpoint + \"_2\" ,F.when(F.col(turnpoint)==0,0).otherwise(F.col(turnpoint + \"_2\")））\n",
    "\n",
    "\n",
    "    to_keep2 = [\"sequencetime\", \"loaddate\" , \"volume\", \"rollingweightedmean\", \"sequencetime_exp\", \"changepoint_confirm\",\n",
    "                \"trendgroup\", \"seq_within_trendgroup\", \"closeprice\", \"openprice\"]\n",
    "    turnpoint_list = [col for col in ts.columns if \"_turnpoint_2\" in col]\n",
    "    to_keep2.extend(turnpoint_list)\n",
    "    ts = ts.select(to_keep2) \n",
    "\n",
    "    ts = ts.withColumn(\"group\", F.lit(\"1\") )\n",
    "    windowSpec = Window.partitionBy(\"group\").orderBy( \"loaddate\")\n",
    "    ts = ts.withColumn(\"lag_closeprice\", F.lag(\"closeprice\" ,1).over(windowSpec))\n",
    "    ts = ts.withColumn(\"pricechange\" ,F.col(\"closeprice\") - F. col(\"lag_closeprice\") )\n",
    "    ts = ts.withColumn(\"gain\" ,F.when(F.col(\"pricechange\") >=0, F.col(\"pricechange\")).otherwise(0))\n",
    "    ts = ts.withColumn (\"loss\", F.when(F.col(\"pricechange\") <0, F.col(\"pricechange\")).otherwise(0) )\n",
    "    ts = ts.withColumn (\"loss\", F.when(F.col(\"loss\")!=0, F.col(\"loss\") * (-1)).otherwise(0) )\n",
    "\n",
    "\n",
    "    ts = ts.orderBy(col(\"loaddate\"))\n",
    "    window_change_10 = Window.partitionBy(\"group\").orderBy(\"loaddate\").rowsBetween(-9, 0)\n",
    "    ts = ts withColumn(\"averagegain\", F.avg(\"gain\").over(window_change_10) )\n",
    "    ts = ts.withColumn (\"averageloss\" , F.avg(\"loss\").over(window_change_10) )\n",
    "    ts = ts.orderBy(col(\"loaddate\"))\n",
    "    ts = ts.withColumn(\"RS\",F.col(\"averagegain\") / F.col(\"averageloss\")) \n",
    "    ts = ts.withColumn (\"RSI10\", 100 - (100 / (1 + F.col(\"RS\")) ) ) \n",
    "    ts = ts.withColumn(\"RSI10\", F.when(F.col(\"averageloss\")==0.0, 100).otherwise(F.col(\"RSI10\")) )\n",
    "    ts = ts.orderBy(col(\"loaddate\"))\n",
    "    window_change_20ma = Window. partitionBy(\"group\").orderBy(\"loaddate\").rowsBetween(-19, 0)\n",
    "    ts = ts.withColumn(\"MA\", F.avg(\"closeprice\").over(window_change_20ma))\n",
    "    ts = ts. withColumn(\"MA_diff\", F.col(\"MA\") - F.col(\"closeprice\"))\n",
    "    ts = ts. withColumn(\"expanding_mean_vol\", F.avg(\"volume\").over(Window.partitionBy(\"group\").orderBy(\"loaddate\").rowsBetween(Window.unboundedPreceding, 0)))\n",
    "    ts = ts.withColumn('Day', F.date_format( 'loaddate', 'EEEE'))\n",
    "\n",
    "    to_keep = ['sequencetime', 'loaddate', 'volume', 'lag', 'rollingweightedmean', ' sequencetime_exp', 'changepoint_confirm', 'trendgroup', 'seq_within_trendgroup', 'closeprice', 'RSI5' , 'RSI10', 'MA diff', 'expanding_mean_vol', 'Day' ]\n",
    "\n",
    "    turnpoint_list = [col for col in ts.columns if \"_turnpoint_2\" in col]\n",
    "    to_keep.extend(turnpoint_list)\n",
    "\n",
    "    final = ts.toPandas()\n",
    "    final = final[to_keep3]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSFRESH package implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user tsfresh \n",
    "@time_estimator\n",
    "def feature_tsfresh(final):\n",
    "    \n",
    "    from tsfresh import extract_relevant_features \n",
    "    from tsfresh import extract features\n",
    "    from tsfresh.utilities.dataframe_functions import roll_time_series\n",
    "    import re\n",
    "    \n",
    "    temp = final[['loaddate','volume']]\n",
    "    temp[\"group\"]=1\n",
    "    df_rolled = roll_time_series(temp, column_id = \"group\", column_sort =\"loaddate\")\n",
    "    df_features = extract_features(df_rolled, column_id = \"id\", column_sort =\"loaddate\")\n",
    "    \n",
    "    df_features = df_features.reset_index()\n",
    "    df_features = df_features.fillna(0)\n",
    "    df_features[\"loaddate\"] = final[\"loaddate\"]\n",
    "    df_features.drop([\"level_0\",\"level_1\"],axis=1,inplace=True)\n",
    "    finaltsfresh = pd.merge(final,df_features, how=\"left\", on=\"loaddate\")\n",
    "    finaltsfresh= pd.concat([finaltsfresh, pd.get_dummies(final['Day'])] ,axis=1)\n",
    "    finaltsfresh = finaltsfresh.drop(\"Day\",axis=1)\n",
    "    \n",
    "    finaltsfresh = finaltsfresh.rename(columns = lambda x:re.sub('[^A-Za z0-9_]+','',x))\n",
    "    finaltsfresh = finaltsfresh.loc[:~finaltsfresh.columns.duplicates()].copy()\n",
    "    \n",
    "    pw = finaltsfresh.copy(depp=True)\n",
    "    pw['loaddate3'] = pw['loaddate'].apply(lambda x: pd.to_datetime())\n",
    "    pw.index = pw.loaddate\n",
    "    pw=pw.drop('loaddate',axis=1)\n",
    "    return pw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = Feature_engineering_volume(equity)\n",
    "pw = feature_tsfresh(final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
